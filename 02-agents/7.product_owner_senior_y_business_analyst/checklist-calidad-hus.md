# Checklist de Calidad para Historias de Usuario

**VersiÃ³n:** 1.0.0  
**Ãšltima actualizaciÃ³n:** 2025-11-08  
**Basado en:** INVEST Criteria, IEEE 29148, Agile Alliance Standards

---

## ğŸ“‹ Instrucciones de Uso

Este checklist debe aplicarse a **cada Historia de Usuario** antes de considerarla lista para desarrollo. Una HU debe cumplir **100% de los criterios obligatorios** para entrar en un sprint.

**Roles que deben validar:**
- Product Owner (todos los criterios)
- Tech Lead (criterios tÃ©cnicos)
- UX Designer (criterios de experiencia)
- QA Lead (criterios de testabilidad)

---

## âœ… Parte 1: INVEST Criteria (Obligatorio)

### I - Independent (Independiente)

- [ ] **La HU puede desarrollarse sin depender de otras HUs en el mismo sprint**
- [ ] Si tiene dependencias, estÃ¡n documentadas en la secciÃ³n "Dependencias"
- [ ] Las dependencias crÃ­ticas estÃ¡n completadas o en progreso avanzado
- [ ] No hay dependencias circulares (A depende de B, B depende de A)

**Preguntas de validaciÃ³n:**
- Â¿Puedo iniciar esta HU sin esperar a que otra termine?
- Â¿Las dependencias estÃ¡n en mÃ³dulos/equipos diferentes que puedan bloquearme?

**Acciones si falla:**
- Identificar quÃ© debe completarse primero
- Considerar dividir la HU en partes independientes
- Documentar dependencias explÃ­citamente

---

### N - Negotiable (Negociable)

- [ ] **La HU describe QUÃ‰ (objetivo), no CÃ“MO (implementaciÃ³n)**
- [ ] Los detalles tÃ©cnicos estÃ¡n abiertos a decisiÃ³n del equipo de desarrollo
- [ ] No especifica tecnologÃ­as concretas (salvo restricciones validadas)
- [ ] Permite diferentes soluciones tÃ©cnicas que cumplan los criterios de aceptaciÃ³n

**Ejemplo:**
```markdown
âŒ RÃGIDO (No negociable):
"Cuando el usuario busca, el sistema debe usar Elasticsearch con sharding 
de 3 nodos y almacenar en Redis con TTL de 5 minutos..."

âœ… FLEXIBLE (Negociable):
"Cuando el usuario busca, los resultados se muestran en <2 segundos 
con disponibilidad 99.9%"
```

**Preguntas de validaciÃ³n:**
- Â¿El equipo tiene libertad para elegir el enfoque tÃ©cnico?
- Â¿Estoy especificando soluciones en lugar de problemas?

**Acciones si falla:**
- Reescribir eliminando detalles de implementaciÃ³n
- Mover detalles tÃ©cnicos a "Notas de diseÃ±o" (sugerencias, no requisitos)

---

### V - Valuable (Valiosa)

- [ ] **El valor de negocio estÃ¡ claramente explicado**
- [ ] La secciÃ³n "ğŸ¯ Valor de Negocio" responde: Â¿Por quÃ© es importante?
- [ ] Se puede medir el impacto (mÃ©trica cuantificable)
- [ ] Un stakeholder no tÃ©cnico entiende el valor sin explicaciones extras
- [ ] La historia aporta valor a un usuario final (no es solo tÃ©cnica)

**MÃ©tricas vÃ¡lidas de valor:**
- Incremento en conversiÃ³n (%)
- ReducciÃ³n de tiempo de tarea (minutos/horas)
- Mejora en NPS/CSAT
- Incremento en revenue ($)
- ReducciÃ³n de costos operativos ($)
- ReducciÃ³n de errores/tickets de soporte (%)

**Preguntas de validaciÃ³n:**
- Â¿Un usuario final notarÃ­a si esta HU no se implementa?
- Â¿Puedo justificar el ROI de esta historia?

**Acciones si falla:**
- Redefinir el beneficio desde la perspectiva del usuario
- Si no hay valor claro, evaluar si es realmente necesaria
- Considerar si es una tarea tÃ©cnica (spike, refactor) en lugar de HU

---

### E - Estimable (Estimable)

- [ ] **El equipo puede estimar esfuerzo con confianza razonable**
- [ ] Los criterios de aceptaciÃ³n son suficientemente claros
- [ ] No hay incertidumbres tÃ©cnicas crÃ­ticas sin resolver
- [ ] Story points estÃ¡n en escala Fibonacci (1, 2, 3, 5, 8, 13, 21)
- [ ] Si estimaciÃ³n es >13 SP, considerar dividir

**SeÃ±ales de que NO es estimable:**
- "No sabemos cÃ³mo hacer esto"
- "Depende de investigar la tecnologÃ­a X"
- "Necesitamos un spike primero"
- Estimaciones varÃ­an >200% entre miembros del equipo

**Preguntas de validaciÃ³n:**
- Â¿Todos los desarrolladores entienden quÃ© construir?
- Â¿Hay tecnologÃ­as/integraciones desconocidas?
- Â¿El alcance es claro o ambiguo?

**Acciones si falla:**
- Crear un **Spike** (timebox de investigaciÃ³n) antes de estimar
- Refinar la historia con mÃ¡s detalles
- Dividir en partes mÃ¡s pequeÃ±as y estimables

---

### S - Small (PequeÃ±a)

- [ ] **La HU puede completarse en 1 sprint (1-2 semanas)**
- [ ] Story points: idealmente 3-8 SP, mÃ¡ximo 13 SP
- [ ] Si es >13 SP, se descompone en HUs mÃ¡s pequeÃ±as
- [ ] Una sola persona/pair puede completarla
- [ ] Tiene un objetivo claro y acotado (no es una Ã©pica disfrazada)

**GuÃ­a de tamaÃ±o:**
| Story Points | Esfuerzo | Tiempo | TamaÃ±o |
|--------------|----------|--------|--------|
| 1-2 SP | Trivial | 0.5-1 dÃ­a | âœ… Muy pequeÃ±a |
| 3-5 SP | Bajo | 1-3 dÃ­as | âœ… PequeÃ±a (ideal) |
| 8 SP | Medio | 3-5 dÃ­as | âš ï¸ Mediana (lÃ­mite) |
| 13 SP | Alto | 5-8 dÃ­as | ğŸ”´ Grande (dividir) |
| 21+ SP | Muy alto | 2+ semanas | ğŸ”´ Ã‰pica (descomponer) |

**TÃ©cnicas de divisiÃ³n:**
- Por rol de usuario (estudiante vs. tutor)
- Por flujo (crear vs. editar vs. eliminar)
- Por complejidad (versiÃ³n simple vs. avanzada)
- Por regla de negocio (validaciÃ³n bÃ¡sica vs. compleja)
- Por UI (pantalla principal vs. modales/secundarias)

**Preguntas de validaciÃ³n:**
- Â¿Puedo demostrar valor al final del sprint?
- Â¿Es lo suficientemente pequeÃ±a para tener feedback rÃ¡pido?

**Acciones si falla:**
- Aplicar tÃ©cnicas de divisiÃ³n
- Crear Ã©pica y descomponerla en 3-8 HUs

---

### T - Testable (Testeable)

- [ ] **Los criterios de aceptaciÃ³n son verificables objetivamente**
- [ ] Cada criterio usa formato Given-When-Then
- [ ] Los "Then" especifican observables claros (no ambiguos)
- [ ] QA puede escribir casos de prueba solo leyendo los AC
- [ ] Incluye escenarios de error y edge cases
- [ ] MÃ©tricas cuantificables cuando aplica (tiempo, cantidad, etc.)

**Ejemplos de criterios testeables vs. no testeables:**

```markdown
âŒ NO TESTEABLE (ambiguo):
"Entonces la pÃ¡gina carga rÃ¡pido"
"El sistema es fÃ¡cil de usar"
"Se muestran resultados relevantes"

âœ… TESTEABLE (especÃ­fico):
"Entonces la pÃ¡gina carga en <2 segundos (medido con Lighthouse)"
"El formulario tiene labels y es navegable con teclado (WCAG 2.1 AA)"
"Los resultados incluyen tutores con rating â‰¥4.0 ordenados por disponibilidad"
```

**Preguntas de validaciÃ³n:**
- Â¿Un tester puede validar esto con un script automatizado?
- Â¿Los criterios son medibles o solo subjetivos?
- Â¿Cubro flujo feliz + errores + edge cases?

**Acciones si falla:**
- Reescribir criterios con mÃ©tricas concretas
- Agregar escenarios de error faltantes
- Consultar con QA para validar claridad

---

## âœ… Parte 2: Formato y Estructura (Obligatorio)

### Formato Given-When-Then (Gherkin)

- [ ] **Todos los criterios de aceptaciÃ³n usan sintaxis Gherkin**
- [ ] Cada escenario tiene nombre descriptivo
- [ ] "Given" establece precondiciones/contexto
- [ ] "When" describe la acciÃ³n del usuario
- [ ] "Then" especifica resultado observable
- [ ] Se usa "Y" para pasos adicionales (no "And" en espaÃ±ol)

**Ejemplo correcto:**
```gherkin
### Escenario 1: Login exitoso con credenciales vÃ¡lidas

Dado que soy un estudiante registrado con email "juan@example.com"
Y mi contraseÃ±a es "Pass123!"
Cuando ingreso mis credenciales en el formulario de login
Y hago clic en "Iniciar sesiÃ³n"
Entonces soy redirigido al dashboard de estudiante
Y veo el mensaje de bienvenida "Hola, Juan"
Y mi sesiÃ³n expira en 30 minutos (token JWT)
```

---

### Trazabilidad

- [ ] **MÃ³dulo identificado** (Auth, Marketplace, Payments, etc.)
- [ ] **Ã‰pica asignada** (a quÃ© grupo de HUs pertenece)
- [ ] **Requisito funcional vinculado** (RF-XXX)
- [ ] **Requisitos no funcionales aplicables** (RNF-XXX si aplica)
- [ ] **Prioridad MoSCoW asignada** (MUST/SHOULD/COULD/WON'T)

---

### EstimaciÃ³n

- [ ] **Story points asignados** (Fibonacci: 1,2,3,5,8,13,21)
- [ ] **Complejidad indicada** (Baja/Media/Alta)
- [ ] Si >13 SP, justificaciÃ³n de por quÃ© no se divide
- [ ] EstimaciÃ³n consensuada (Planning Poker o similar)

---

### Dependencias

- [ ] **Dependencias hacia atrÃ¡s documentadas** (quÃ© debe completarse antes)
- [ ] **Dependencias hacia adelante** (quÃ© bloquea esta HU)
- [ ] **Historias relacionadas listadas** (mismo mÃ³dulo/flujo)
- [ ] Dependencias crÃ­ticas con riesgo de bloqueo identificadas

---

### Definition of Done

- [ ] **Checklist de DoD incluida**
- [ ] Incluye: cÃ³digo, tests, documentaciÃ³n, deploy, demo
- [ ] Criterios tÃ©cnicos (cobertura, linters, seguridad)
- [ ] Criterios de calidad (performance, accesibilidad)
- [ ] ValidaciÃ³n por stakeholders

---

## âœ… Parte 3: Calidad de RedacciÃ³n (Obligatorio)

### Lenguaje y Claridad

- [ ] **Usa lenguaje de negocio** (no jerga tÃ©cnica innecesaria)
- [ ] Un stakeholder no tÃ©cnico entiende la HU sin explicaciones
- [ ] El tÃ­tulo es auto-explicativo (mÃ¡ximo 60 caracteres)
- [ ] No hay acrÃ³nimos sin definir
- [ ] Lenguaje consistente con el dominio del proyecto

**Ejemplos:**
```markdown
âŒ TÃ‰CNICO (malo):
"Como usuario, quiero que el endpoint /api/auth/login retorne 
JWT en header Authorization..."

âœ… NEGOCIO (bueno):
"Como estudiante, quiero iniciar sesiÃ³n con mi email para 
acceder a mi dashboard personalizado"
```

---

### Perspectiva del Usuario

- [ ] **La HU estÃ¡ escrita desde el punto de vista del usuario final**
- [ ] No dice "Como desarrollador..." (esas son tareas tÃ©cnicas)
- [ ] No dice "Como sistema..." (foco en humanos, no mÃ¡quinas)
- [ ] Especifica ROL concreto (Estudiante, Tutor, Admin, no "Usuario")

---

### Beneficio ExplÃ­cito

- [ ] **La clÃ¡usula "Para [beneficio]" estÃ¡ presente y clara**
- [ ] El beneficio es tangible (no genÃ©rico como "tener funcionalidad")
- [ ] Conecta con objetivos de negocio o del usuario

**Ejemplos:**
```markdown
âŒ VAGO:
"Para tener la funcionalidad de bÃºsqueda"

âœ… ESPECÃFICO:
"Para encontrar tutores calificados en menos de 30 segundos 
y aumentar mi confianza en la plataforma"
```

---

## âœ… Parte 4: Cobertura de Escenarios (Recomendado)

### Escenarios MÃ­nimos

- [ ] **Escenario 1: Flujo feliz** (todo funciona correctamente)
- [ ] **Escenario 2: Flujo alternativo** (variaciÃ³n vÃ¡lida del flujo)
- [ ] **Escenario 3: Manejo de errores** (entrada invÃ¡lida, error de servicio)
- [ ] **Escenario 4: Edge cases** (valores lÃ­mite, casos extremos)

**Ejemplo de cobertura completa:**
```gherkin
Escenario 1: Pago exitoso con tarjeta vÃ¡lida (flujo feliz)
Escenario 2: Pago con cupÃ³n de descuento (alternativo)
Escenario 3: Pago rechazado por tarjeta expirada (error)
Escenario 4: Pago con monto mÃ­nimo ($500 COP) (edge case)
```

---

### Requisitos No Funcionales en AC

- [ ] **Performance:** Tiempos de respuesta especificados (si aplica)
- [ ] **Seguridad:** Validaciones, encriptaciÃ³n (si aplica)
- [ ] **Accesibilidad:** WCAG 2.1 AA, navegaciÃ³n con teclado (si aplica)
- [ ] **Usabilidad:** Mensajes de error claros, feedback visual

---

## âœ… Parte 5: Completitud (Recomendado)

### Secciones Obligatorias

- [ ] ğŸ“‹ Historia de Usuario (Como-Quiero-Para)
- [ ] ğŸ¯ Valor de Negocio
- [ ] âœ… Criterios de AceptaciÃ³n (3-5 escenarios)
- [ ] ğŸ”— Trazabilidad (mÃ³dulo, Ã©pica, RF, prioridad)
- [ ] ğŸ“Š EstimaciÃ³n (story points, complejidad)
- [ ] ğŸ”„ Dependencias
- [ ] âœ”ï¸ Definition of Done

### Secciones Opcionales pero Recomendadas

- [ ] ğŸ“ DescripciÃ³n Detallada
- [ ] ğŸ§ª Notas de Testing
- [ ] ğŸ¨ Notas de DiseÃ±o (wireframes, flujos UX)
- [ ] âš ï¸ Riesgos y Supuestos
- [ ] ğŸ“Œ Etiquetas (tags)

---

## âœ… Parte 6: ValidaciÃ³n Cross-Funcional (Obligatorio)

### Checkpoint con Desarrollo

- [ ] **Un desarrollador junior puede entender quÃ© construir**
- [ ] Los criterios de aceptaciÃ³n son suficientemente claros
- [ ] No hay ambigÃ¼edades tÃ©cnicas crÃ­ticas
- [ ] El alcance es realista para el sprint

**Pregunta clave:** "Â¿PodrÃ­a un dev junior implementar esto sin preguntarme 10 veces?"

---

### Checkpoint con QA

- [ ] **Un tester puede escribir casos de prueba solo leyendo los AC**
- [ ] Los escenarios cubren happy path + errores + edge cases
- [ ] Los criterios son verificables (no subjetivos)
- [ ] Hay datos de prueba disponibles o fÃ¡ciles de crear

**Pregunta clave:** "Â¿QA puede automatizar estos tests sin inventar criterios?"

---

### Checkpoint con UX/DiseÃ±o

- [ ] **Un diseÃ±ador UX sabe quÃ© pantallas/flujos crear**
- [ ] Los wireframes existen o estÃ¡n en progreso
- [ ] El flujo de usuario es claro y lÃ³gico
- [ ] Se considerÃ³ accesibilidad (WCAG 2.1)

**Pregunta clave:** "Â¿UX puede diseÃ±ar la interfaz sin asumir comportamientos?"

---

### Checkpoint con Negocio/PO

- [ ] **Un stakeholder de negocio valida el valor sin explicaciones extras**
- [ ] La prioridad es correcta (alineada con roadmap)
- [ ] El valor de negocio justifica el esfuerzo
- [ ] Los criterios de aceptaciÃ³n reflejan necesidades reales

**Pregunta clave:** "Â¿El CEO/cliente entenderÃ­a por quÃ© estamos construyendo esto?"

---

## ğŸ“Š Scoring de Calidad

### Nivel de Cumplimiento

| Criterios Cumplidos | Nivel | AcciÃ³n |
|---------------------|-------|--------|
| 100% (Parte 1-3) | â­â­â­ Excelente | âœ… Lista para sprint |
| 90-99% | â­â­ Buena | âš ï¸ Refinar detalles menores |
| 70-89% | â­ Regular | ğŸ”´ Requiere refinamiento |
| <70% | âŒ Insuficiente | ğŸš« No lista, rehacer |

---

## ğŸ”„ Proceso de Refinamiento

Si una HU **NO pasa** el checklist:

1. **Identificar** quÃ© criterios especÃ­ficos fallan
2. **Refinar** la HU con el equipo (PO + Dev + UX + QA)
3. **Documentar** cambios en "Historial de Cambios"
4. **Re-validar** con este checklist
5. **Aprobar** solo cuando cumple 100% de Parte 1-3

---

## ğŸ“š Referencias

- **INVEST Criteria:** [Bill Wake, 2003](https://xp123.com/articles/invest-in-good-stories-and-smart-tasks/)
- **User Story Mapping:** [Jeff Patton, 2014](https://www.jpattonassociates.com/user-story-mapping/)
- **Gherkin Syntax:** [Cucumber BDD](https://cucumber.io/docs/gherkin/)
- **IEEE 29148:2018:** Requirements Engineering Standard
- **Agile Alliance:** [User Story Definition](https://www.agilealliance.org/glossary/user-stories/)

---

## ğŸ“ Plantilla de Firma de AprobaciÃ³n

```markdown
## âœ… AprobaciÃ³n de Historia de Usuario

**Historia:** HU-XXX - [TÃ­tulo]

| Rol | Nombre | AprobaciÃ³n | Fecha | Comentarios |
|-----|--------|------------|-------|-------------|
| Product Owner | [Nombre] | âœ… / âŒ | 2025-11-08 | Valor de negocio validado |
| Tech Lead | [Nombre] | âœ… / âŒ | 2025-11-08 | EstimaciÃ³n realista |
| QA Lead | [Nombre] | âœ… / âŒ | 2025-11-08 | Criterios testeables |
| UX Designer | [Nombre] | âœ… / âŒ | 2025-11-08 | Flujo claro y usable |

**DecisiÃ³n Final:** âœ… APROBADA para Sprint X  
**PrÃ³ximo paso:** Planning Poker para estimar SP
```

---

**VersiÃ³n del Checklist:** 1.0.0  
**Mantenido por:** MÃ©todo CEIBA - User Stories Agent  
**Ãšltima revisiÃ³n:** 2025-11-08
