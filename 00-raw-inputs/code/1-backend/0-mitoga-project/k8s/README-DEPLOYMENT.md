# ğŸš€ GUÃA DE DEPLOYMENT CI/CD - MITOGA BACKEND

**Fecha:** 12 de noviembre de 2025  
**DevSecOps:** Senior On-Premise  
**Cluster:** K3s - 192.168.18.126  
**Namespace:** mi-toga  

---

## ğŸ“‹ RESUMEN EJECUTIVO

Se ha configurado un pipeline CI/CD completo para el proyecto Mitoga Backend con las siguientes caracterÃ­sticas:

âœ… **Namespace aislado** con Resource Quotas y Limit Ranges  
âœ… **RBAC configurado** con Service Account para deployments  
âœ… **ConfigMaps y Secrets** para configuraciÃ³n  
âœ… **Deployment** con 2 replicas, health checks y security context  
âœ… **Service ClusterIP** para comunicaciÃ³n interna  
âœ… **Ingress con TLS** (api.mitoga.local)  
âœ… **HPA** (2-10 replicas basado en CPU/Memoria)  
âœ… **PDB** (Pod Disruption Budget para alta disponibilidad)  
âœ… **Network Policies** (deny-all + allow especÃ­ficos)  
âœ… **ServiceMonitor** con alertas Prometheus  
âœ… **Jenkinsfile** con 10 stages completos  

---

## ğŸ—ï¸ ARQUITECTURA DESPLEGADA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERNET / USERS                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAEFIK INGRESS (443/80)                      â”‚
â”‚                    192.168.18.201                                â”‚
â”‚                    api.mitoga.local                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ TLS/SSL
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NAMESPACE: mi-toga                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SERVICE: mitoga-backend-service (ClusterIP:8080)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DEPLOYMENT: mitoga-backend (2-10 replicas)              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚   POD 1    â”‚  â”‚   POD 2    â”‚  â”‚   POD N    â”‚         â”‚ â”‚
â”‚  â”‚  â”‚ Spring Bootâ”‚  â”‚ Spring Bootâ”‚  â”‚ Spring Bootâ”‚         â”‚ â”‚
â”‚  â”‚  â”‚  Java 21   â”‚  â”‚  Java 21   â”‚  â”‚  Java 21   â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚  HPA: Auto-scaling basado en CPU (70%) y Memoria (80%)         â”‚
â”‚  PDB: MÃ­nimo 1 pod disponible durante disruptions               â”‚
â”‚  NetworkPolicy: Allow Traefik, Prometheus, DB, Redis            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DEPENDENCIAS EXTERNAS                               â”‚
â”‚  â€¢ PostgreSQL (databases namespace)                              â”‚
â”‚  â€¢ Redis (databases namespace)                                   â”‚
â”‚  â€¢ Vault (cicd namespace)                                        â”‚
â”‚  â€¢ Prometheus (cicd namespace)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ ARCHIVOS CREADOS

### Manifiestos Kubernetes (k8s/)
```
k8s/
â”œâ”€â”€ 00-namespace.yaml         # Namespace + ResourceQuota + LimitRange
â”œâ”€â”€ 01-serviceaccount.yaml    # ServiceAccount + Role + RoleBinding
â”œâ”€â”€ 02-configmap.yaml         # application.yml + prometheus config
â”œâ”€â”€ 03-secrets.yaml           # DB, Redis, Mail, Vault, JWT secrets
â”œâ”€â”€ 04-deployment.yaml        # Deployment principal (2 replicas)
â”œâ”€â”€ 05-service.yaml           # ClusterIP Service + Headless
â”œâ”€â”€ 06-ingress.yaml           # Ingress + Traefik Middlewares
â”œâ”€â”€ 07-hpa-pdb.yaml           # HPA (2-10 replicas) + PDB
â”œâ”€â”€ 08-networkpolicy.yaml     # Network Policies
â”œâ”€â”€ 09-servicemonitor.yaml    # ServiceMonitor + PrometheusRule
â””â”€â”€ init-db.sql               # Script inicializaciÃ³n PostgreSQL
```

### Pipeline CI/CD
```
Jenkinsfile                   # Pipeline completo con 10 stages
```

---

## ğŸš€ PASOS DE DEPLOYMENT

### PASO 1: Aplicar Manifiestos K8s

```bash
# Conectar al servidor
ssh wtorresa@192.168.18.126

# Aplicar manifiestos en orden
kubectl apply -f k8s/00-namespace.yaml
kubectl apply -f k8s/01-serviceaccount.yaml
kubectl apply -f k8s/02-configmap.yaml
kubectl apply -f k8s/03-secrets.yaml

# âš ï¸ IMPORTANTE: Editar secrets antes de aplicar en producciÃ³n
kubectl edit secret -n mi-toga mitoga-db-credentials
kubectl edit secret -n mi-toga mitoga-redis-credentials
kubectl edit secret -n mi-toga mitoga-mail-credentials
kubectl edit secret -n mi-toga mitoga-jwt-keys

# Aplicar deployment y servicios
kubectl apply -f k8s/04-deployment.yaml
kubectl apply -f k8s/05-service.yaml
kubectl apply -f k8s/06-ingress.yaml
kubectl apply -f k8s/07-hpa-pdb.yaml
kubectl apply -f k8s/08-networkpolicy.yaml
kubectl apply -f k8s/09-servicemonitor.yaml
```

### PASO 2: Configurar Base de Datos PostgreSQL

```bash
# Conectar a PostgreSQL
kubectl exec -it -n databases postgres-dbbfb4c95-69cck -- psql -U admin postgres

# Ejecutar desde psql:
CREATE DATABASE mitoga_db;
CREATE USER mitoga_user WITH ENCRYPTED PASSWORD 'changeme_mitoga_2025';
GRANT ALL PRIVILEGES ON DATABASE mitoga_db TO mitoga_user;

\c mitoga_db
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO mitoga_user;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO mitoga_user;
\q
```

### PASO 3: Configurar Credenciales en Jenkins

```bash
# Acceder a Jenkins
http://192.168.18.203:8080

# Agregar credenciales en Jenkins > Credentials > Global
1. github-mitoga-credentials (Username with password)
   - Username: mlditsoft-mitoga
   - Password: [GitHub Personal Access Token]

2. docker-registry-credentials (Username with password)
   - Username: admin
   - Password: [Docker Registry password]

3. k3s-kubeconfig-credentials (Secret file)
   - File: ~/.kube/config del servidor K3s

4. sonarqube-token (Secret text)
   - Secret: [SonarQube authentication token]
```

### PASO 4: Crear Jenkins Pipeline Job

```bash
1. New Item > Multibranch Pipeline
2. Name: mitoga-backend-pipeline
3. Branch Sources > Add source > Git
   - Project Repository: https://github.com/mlditsoft-mitoga/mitoga_core.git
   - Credentials: github-mitoga-credentials
4. Build Configuration:
   - Mode: by Jenkinsfile
   - Script Path: 00-raw-inputs/code/1-backend/0-mitoga-project/Jenkinsfile
5. Scan Multibranch Pipeline Triggers:
   - âœ… Periodically if not otherwise run
   - Interval: 5 minutes
6. Save
```

### PASO 5: Configurar DNS/Hosts

```bash
# En tu mÃ¡quina local (Windows):
notepad C:\Windows\System32\drivers\etc\hosts

# Agregar lÃ­nea:
192.168.18.201  api.mitoga.local mitoga.mitoga.local

# En Linux/Mac:
sudo nano /etc/hosts
# Agregar la misma lÃ­nea
```

### PASO 6: Ejecutar Primer Deployment

```bash
# OpciÃ³n A: Via Jenkins (RECOMENDADO)
1. Ir a Jenkins > mitoga-backend-pipeline > master
2. Click en "Build with Parameters"
3. DEPLOY_ENVIRONMENT: production
4. SKIP_TESTS: false
5. Build Now

# OpciÃ³n B: Via kubectl manual (solo para testing)
kubectl set image deployment/mitoga-backend \
    mitoga-backend=192.168.18.126:5000/mitoga-backend:latest \
    -n mi-toga

kubectl rollout status deployment/mitoga-backend -n mi-toga
```

---

## âœ… VERIFICACIÃ“N POST-DEPLOYMENT

### Verificar Pods
```bash
kubectl get pods -n mi-toga
# Esperado: 2 pods Running

kubectl describe pod -n mi-toga -l app=mitoga-backend
# Verificar eventos, estado, recursos
```

### Verificar Services
```bash
kubectl get svc -n mi-toga
# Esperado: mitoga-backend-service ClusterIP

kubectl get endpoints -n mi-toga
# Debe mostrar IPs de pods
```

### Verificar Ingress
```bash
kubectl get ingress -n mi-toga
# ADDRESS debe ser 192.168.18.201

kubectl describe ingress mitoga-backend-ingress -n mi-toga
```

### Health Checks
```bash
# Health endpoint (via port-forward)
kubectl port-forward -n mi-toga svc/mitoga-backend-service 8080:8080

# En otra terminal:
curl http://localhost:8080/actuator/health
# Esperado: {"status":"UP"}

# Via Ingress (HTTPS)
curl -k https://api.mitoga.local/actuator/health
```

### Logs
```bash
# Ver logs en tiempo real
kubectl logs -f -n mi-toga -l app=mitoga-backend

# Logs de pod especÃ­fico
POD_NAME=$(kubectl get pods -n mi-toga -l app=mitoga-backend -o jsonpath='{.items[0].metadata.name}')
kubectl logs -f -n mi-toga $POD_NAME
```

### MÃ©tricas Prometheus
```bash
# Verificar ServiceMonitor
kubectl get servicemonitor -n mi-toga

# Acceder a Prometheus
http://192.168.18.126:30900

# Query ejemplos:
- up{job="mitoga-backend-service"}
- jvm_memory_used_bytes{area="heap"}
- http_server_requests_seconds_count
```

### Grafana Dashboard
```bash
# Acceder a Grafana
http://192.168.18.126:30300

# Crear dashboard con queries:
- JVM Heap Memory: jvm_memory_used_bytes{area="heap",namespace="mi-toga"}
- HTTP Requests: rate(http_server_requests_seconds_count{namespace="mi-toga"}[5m])
- Response Time: histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))
```

---

## ğŸ”’ SEGURIDAD

### Network Policies Aplicadas
âœ… Deny all traffic por defecto  
âœ… Allow desde Traefik Ingress  
âœ… Allow desde Prometheus  
âœ… Allow hacia PostgreSQL  
âœ… Allow hacia Redis  
âœ… Allow hacia Vault  
âœ… Allow HTTPS saliente (443, 587, 465)  

### Security Context
âœ… runAsNonRoot: true  
âœ… readOnlyRootFilesystem: true  
âœ… runAsUser: 65532 (distroless nonroot)  
âœ… capabilities dropped: ALL  
âœ… seccompProfile: RuntimeDefault  

### Secrets Management
âš ï¸ **CAMBIAR EN PRODUCCIÃ“N:**
- DB_PASSWORD en `mitoga-db-credentials`
- REDIS_PASSWORD en `mitoga-redis-credentials`
- MAIL_PASSWORD en `mitoga-mail-credentials`
- JWT_SECRET en `mitoga-jwt-keys`
- VAULT_TOKEN en `mitoga-vault-token`

---

## ğŸ“Š MONITOREO

### Alertas Configuradas (PrometheusRule)
1. **MitogaBackendDown** - Pod down > 1min (CRITICAL)
2. **MitogaBackendHighCPU** - CPU > 80% por 5min (WARNING)
3. **MitogaBackendHighMemory** - Heap > 90% por 5min (WARNING)
4. **MitogaBackendHighErrorRate** - Errores > 10/sec por 5min (CRITICAL)
5. **MitogaBackendSlowResponse** - p95 > 2 sec por 5min (WARNING)
6. **MitogaBackendDBPoolExhaustion** - Pool > 90% por 5min (CRITICAL)
7. **MitogaBackendHighGCTime** - GC > 50% tiempo por 5min (WARNING)

### Endpoints de Monitoreo
```
/actuator/health              # Health check
/actuator/health/liveness     # Liveness probe
/actuator/health/readiness    # Readiness probe
/actuator/prometheus          # MÃ©tricas Prometheus
/actuator/metrics             # MÃ©tricas individuales
/actuator/info                # InformaciÃ³n de la app
```

---

## ğŸ”„ OPERACIONES

### Escalar Manualmente
```bash
kubectl scale deployment mitoga-backend --replicas=5 -n mi-toga
```

### Rolling Update
```bash
kubectl set image deployment/mitoga-backend \
    mitoga-backend=192.168.18.126:5000/mitoga-backend:v2.0.0 \
    -n mi-toga

kubectl rollout status deployment/mitoga-backend -n mi-toga
```

### Rollback
```bash
# Ver historial
kubectl rollout history deployment/mitoga-backend -n mi-toga

# Rollback a versiÃ³n anterior
kubectl rollout undo deployment/mitoga-backend -n mi-toga

# Rollback a versiÃ³n especÃ­fica
kubectl rollout undo deployment/mitoga-backend --to-revision=3 -n mi-toga
```

### Restart Pods
```bash
kubectl rollout restart deployment/mitoga-backend -n mi-toga
```

### Debug Pod
```bash
# Shell interactivo (distroless no tiene shell, usar debug container)
kubectl debug -it -n mi-toga $POD_NAME --image=busybox:1.36 --target=mitoga-backend

# Exec comando
kubectl exec -n mi-toga $POD_NAME -- wget -qO- http://localhost:8080/actuator/health
```

---

## ğŸ“ PIPELINE CI/CD - JENKINSFILE

### 10 Stages Configurados:

1. **ğŸ“¥ Checkout** - Clonar repositorio GitHub
2. **ğŸ”¨ Build** - Compilar con Gradle
3. **ğŸ§ª Tests** - Unit + Integration tests
4. **ğŸ“Š SonarQube** - Code quality analysis
5. **âœ… Quality Gate** - Verificar quality gate
6. **ğŸ³ Docker Build** - Construir imagen distroless
7. **ğŸ”’ Trivy Scan** - Security scanning (HIGH, CRITICAL)
8. **ğŸ“¤ Push Registry** - Push a Docker Registry local
9. **ğŸš€ Deploy K3s** - Aplicar manifiestos + rolling update
10. **âœ… Smoke Tests** - Health checks post-deployment

### ParÃ¡metros del Pipeline:
- `DEPLOY_ENVIRONMENT`: development | staging | production
- `SKIP_TESTS`: Skip tests (no recomendado)
- `SKIP_SONAR`: Skip SonarQube
- `SKIP_TRIVY`: Skip security scan
- `FORCE_DEPLOY`: Force deploy (ignora fallos)

---

## ğŸ¯ PRÃ“XIMOS PASOS

### Corto Plazo (Esta Semana)
- [ ] Configurar Redis para cachÃ©
- [ ] Completar Ingress para Prometheus y Portainer
- [ ] Extender Network Policies a otros namespaces
- [ ] Configurar backup automÃ¡tico con Velero

### Medio Plazo (PrÃ³ximas 2 Semanas)
- [ ] Integrar SonarQube en cluster
- [ ] Instalar Trivy en Jenkins agent
- [ ] Configurar alertas en Slack/Email
- [ ] Implementar GitOps con ArgoCD

### Largo Plazo (PrÃ³ximo Mes)
- [ ] Migrar a cluster multi-nodo (HA)
- [ ] Implementar Blue-Green deployments
- [ ] Configurar Disaster Recovery completo
- [ ] Optimizar costos y recursos

---

## ğŸ“š DOCUMENTACIÃ“N ADICIONAL

- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [K3s Documentation](https://docs.k3s.io/)
- [Traefik Ingress](https://doc.traefik.io/traefik/providers/kubernetes-ingress/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [Jenkins Pipeline Syntax](https://www.jenkins.io/doc/book/pipeline/syntax/)

---

**Configurado por:** DevSecOps Senior  
**Fecha:** 12 de noviembre de 2025  
**VersiÃ³n:** 1.0.0  
**Namespace:** mi-toga  
**Cluster:** K3s @ 192.168.18.126  

ğŸ‰ **CI/CD Pipeline Ready for Production!**
